{
 "cells": [
  {
   "cell_type": "raw",
   "id": "77580d95",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with \n",
    "an example."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9574c940",
   "metadata": {},
   "source": [
    "Probability Mass Function (PMF):\n",
    "\n",
    "=> PMF is used to describe the probability distribution of a discrete random variable. It associates     each possible value of the random variable with its probability.\n",
    "=> PMF is typically represented as a function that takes a specific value of the random variable as     input and returns the probability of that value occurring.\n",
    "=> The sum of probabilities over all possible values of the random variable is equal to 1.\n",
    "    eg, Rolling the fair six sided dice.\n",
    "    \n",
    "Probability Density Function (PDF):\n",
    "\n",
    "=> PDF is used to describe the probability distribution of a continuous random variable. Instead of     assigning probabilities to specific values, it assigns probabilities to intervals or ranges of         values.\n",
    "=> The PDF is represented as a function that, when integrated over a specific range, gives the           probability of the random variable falling within that range.\n",
    "=> The area under the PDF curve over its entire domain is equal to 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff753413",
   "metadata": {},
   "source": [
    "#### Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4069ead",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF), often denoted as F(x), is a concept used in probability and statistics to describe the cumulative probability distribution of a random variable. It provides information about the probability that the random variable takes on a value less than or equal to a specific value x.\n",
    "\n",
    "Example:\n",
    "Let's consider the example of rolling a fair six-sided die. The random variable X represents the outcome of the die roll, which can take values from 1 to 6. The CDF for this example would be:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "F(1) = P(X ≤ 1) = 1/6 (since there's one way to get a 1 on the die)\n",
    "F(2) = P(X ≤ 2) = 2/6 (since there are two ways to get a 1 or 2 on the die)\n",
    "F(3) = P(X ≤ 3) = 3/6 (three ways to get 1, 2, or 3)\n",
    "F(4) = P(X ≤ 4) = 4/6\n",
    "F(5) = P(X ≤ 5) = 5/6\n",
    "F(6) = P(X ≤ 6) = 6/6 = 1 (since all outcomes are less than or equal to 6)\n",
    "\n",
    "So, the CDF for rolling a fair six-sided die would be represented as a step function, which starts at 0, increases with each possible value of X, and reaches 1 when all possible outcomes have been considered.\n",
    "\n",
    "Why CDF is used:\n",
    "\n",
    "=> The CDF is a fundamental concept in probability and statistics and is widely used for various purposes:\n",
    "=> It provides a complete description of the probability distribution of a random variable.\n",
    "=> It allows you to find the probability that a random variable falls within a specific range or is     less than a certain value.\n",
    "=> It's useful for calculating percentiles, which help in understanding where a particular value         stands relative to the entire distribution.\n",
    "=> It can be used to find the expected value (mean) and variance of a random variable.\n",
    "=> In some cases, CDFs are used to generate random numbers that follow a particular probability           distribution."
   ]
  },
  {
   "cell_type": "raw",
   "id": "78117fc5",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model? \n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d95a594f",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution or the bell curve, is a widely used probability distribution in statistics and is applicable in various real-world situations. It is characterized by its bell-shaped curve and is defined by two parameters: the mean (μ) and the standard deviation (σ). The parameters of the normal distribution play a crucial role in shaping the distribution.\n",
    "\n",
    "Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "=> Height of a Population: The heights of individuals in a large population often follow a normal       distribution. The mean height (μ) represents the average height, and the standard deviation (σ)       indicates the spread or variability in heights.\n",
    "\n",
    "=> IQ Scores: IQ scores in the population are often modeled by a normal distribution. The mean IQ score is typically set at 100, and the standard deviation is used to describe the distribution of scores.\n",
    "\n",
    "=> Measurement Errors: When making measurements in science or engineering, the errors are often normally distributed. The mean error (μ) is typically assumed to be zero, and the standard deviation (σ) represents the precision of the measurement instrument.\n",
    "\n",
    "=> Test Scores: In educational testing, test scores for a large population can often be modeled as a normal distribution. The mean score represents the average performance, and the standard deviation indicates the spread of scores.\n",
    "\n",
    "=> Residuals in Regression Analysis: In regression analysis, the distribution of residuals (the differences between observed and predicted values) is often assumed to be normally distributed. The mean of the residuals is ideally zero, and the standard deviation reflects the random variation in the data.\n",
    "\n",
    "=> Financial Markets: In finance, stock returns are often assumed to be normally distributed. The mean return represents the expected return on an investment, and the standard deviation reflects the volatility or risk associated with the investment.\n",
    "\n",
    "The parameters of the normal distribution, mean (μ) and standard deviation (σ), determine the shape of the distribution as follows:\n",
    "\n",
    "=> Mean (μ): The mean represents the center of the distribution. It determines the location of the peak of the bell curve. If μ is higher, the peak of the curve shifts to the right, and if μ is lower, the peak shifts to the left.\n",
    "\n",
    "=> Standard Deviation (σ): The standard deviation determines the spread or width of the distribution. A larger σ results in a wider and flatter curve, indicating more variability in the data. Conversely, a smaller σ results in a narrower and taller curve, indicating less variability."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b52e442f",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal \n",
    "Distribution."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c35cd21e",
   "metadata": {},
   "source": [
    "The Normal Distribution, also known as the Gaussian distribution or the bell curve, is a fundamental concept in statistics and probability theory. It is important for several reasons:\n",
    "\n",
    "=> Common Natural Phenomenon: The Normal Distribution describes the natural variability found in many phenomena in the real world. It is a way to model how data tends to cluster around a central value, with fewer data points as you move further away from the center. Many random processes, when observed over a sufficiently large number of trials, tend to follow a normal distribution. This makes it a crucial tool for understanding and predicting a wide range of phenomena.\n",
    "\n",
    "=> Central Limit Theorem: The Normal Distribution is central to the concept of the Central Limit Theorem, which states that the distribution of sample means from a population will approach a normal distribution as the sample size increases, regardless of the shape of the original population's distribution. This property is vital in inferential statistics, hypothesis testing, and confidence interval estimation.\n",
    "\n",
    "=> Statistical Inference: In statistical analysis, many hypothesis tests, confidence intervals, and regression analyses assume that the data follows a normal distribution. This assumption simplifies calculations and makes these methods widely applicable in practice.\n",
    "\n",
    "=> Risk Assessment and Decision-Making: The Normal Distribution is used in risk assessment, particularly in finance. It helps in modeling the distribution of returns on investments and calculating the probability of various outcomes. Many risk management models, such as Value at Risk (VaR), rely on normal distributions to estimate potential losses.\n",
    "\n",
    "=> Quality Control and Process Monitoring: In manufacturing and quality control, the Normal Distribution is used to monitor and control processes. Variability in product quality is often assumed to follow a normal distribution. By setting control limits, manufacturers can detect when a process is deviating from the norm, which can help prevent defects and improve product quality.\n",
    "\n",
    "=> Biological and Social Sciences: Many characteristics in the biological and social sciences, such as human height, IQ scores, and blood pressure, tend to follow a normal distribution. This makes the normal distribution a useful tool for modeling and analyzing such data.\n",
    "\n",
    "Real-life examples of Normal Distribution:\n",
    "\n",
    "Height of Adults: The distribution of heights in a population often follows a normal distribution, with the majority of people clustered around the average height and fewer people at extremely tall or short heights.\n",
    "\n",
    "IQ Scores: IQ scores are designed to follow a normal distribution, with the mean IQ set at 100. The majority of people have scores close to 100, while fewer individuals have very high or very low IQ scores.\n",
    "\n",
    "Blood Pressure: The distribution of blood pressure in a population is often close to normal. Most people have blood pressure readings around a central value, with fewer individuals having extremely high or low blood pressure.\n",
    "\n",
    "Exam Scores: In a large group of students taking an exam, the scores often approximate a normal distribution, with most students scoring near the average and fewer students scoring at the extremes.\n",
    "\n",
    "Financial Returns: In finance, daily or monthly returns on investments, like stocks, often follow a normal distribution, which is essential for risk management and portfolio optimization.\n",
    "\n",
    "Understanding the Normal Distribution is crucial for making informed decisions, conducting statistical analyses, and modeling various real-world phenomena accurately."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3755e4a",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli \n",
    "Distribution and Binomial Distribution"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c69807f",
   "metadata": {},
   "source": [
    "The Bernoulli Distribution is a probability distribution that describes a random experiment with only two possible outcomes: success and failure. It is named after the Swiss mathematician Jacob Bernoulli. In this distribution, there is a single trial with a binary outcome, where the probability of success is denoted by \"p,\" and the probability of failure is denoted by \"q,\" where q = 1 - p.\n",
    "\n",
    "the difference between Bernoulli Distribution and Binomial Distribution:\n",
    "\n",
    "=> Number of Trials:\n",
    "\n",
    "Bernoulli Distribution: Describes a single trial with two possible outcomes (success and failure).\n",
    "Binomial Distribution: Describes the number of successes in a fixed number of independent Bernoulli trials (repeated Bernoulli experiments).\n",
    "\n",
    "=> Parameters:\n",
    "\n",
    "Bernoulli Distribution: It has a single parameter, p, representing the probability of success in a single trial.\n",
    "Binomial Distribution: It has two parameters, n (the number of trials) and p (the probability of success in each trial).\n",
    "\n",
    "=> Outcome Space:\n",
    "\n",
    "Bernoulli Distribution: The outcome space consists of only two possible values: 0 and 1 (representing failure and success).\n",
    "Binomial Distribution: The outcome space includes the number of successes (0, 1, 2, ..., n) in a fixed number of trials.\n",
    "\n",
    "=> Purpose:\n",
    "\n",
    "Bernoulli Distribution: Used to model the outcome of a single binary trial, such as a coin toss or a pass/fail experiment.\n",
    "Binomial Distribution: Used to model the number of successes in a series of independent Bernoulli trials, like counting the number of heads in multiple coin tosses.\n",
    "\n",
    "=> Probability Mass Function:\n",
    "\n",
    "Bernoulli Distribution: Has a simple probability mass function that describes the outcome of a single trial.\n",
    "Binomial Distribution: Has a more complex probability mass function that calculates the probability of achieving k successes in n trials.\n",
    "\n",
    "In summary, the Bernoulli Distribution is a special case of the Binomial Distribution when the number of trials (n) is equal to 1. The Bernoulli Distribution is used to model individual binary events, while the Binomial Distribution is used to model the number of successes in a fixed number of such events."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8df52b7",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset \n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater \n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba2e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884edcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=60\n",
    "mean=50\n",
    "std=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a5422fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # As it is normally distributed we can find z-score:-\n",
    "     #z=X-mean/std\n",
    "  \n",
    "  #z-score=\n",
    "z_score = (X-mean)/std\n",
    "z_score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59bdfac2",
   "metadata": {},
   "source": [
    "Now looking the value of 1 in z-table is .84134.\n",
    "that means equal to 84.134%.\n",
    "probability of any random value greater than 60 is 84.134%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62c0327",
   "metadata": {},
   "source": [
    "#### Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6c6c7e0",
   "metadata": {},
   "source": [
    "The Uniform Distribution is a probability distribution in which all outcomes or values within a specified range are equally likely. In other words, in a uniform distribution, every value has the same probability of occurring. It is a simple and straightforward distribution because it assigns an equal probability density to each possible outcome.\n",
    "\n",
    "Characteristics of the Uniform Distribution:\n",
    "\n",
    "=> Equal Probability: In a uniform distribution, all values within a given interval have the same probability of occurring. This means that no particular value is more likely than any other value in the range.\n",
    "\n",
    "=> Defined Interval: The uniform distribution is defined within a specific interval, typically denoted as [a, b], where \"a\" represents the minimum value and \"b\" represents the maximum value. Values outside this interval have a probability of 0.\n",
    "\n",
    "=> Constant Probability Density: The probability density function (PDF) is constant within the interval [a, b] and zero outside of it. The PDF is defined as 1 / (b - a) for all values within the interval [a, b].\n",
    "\n",
    "Example of the Uniform Distribution:\n",
    "\n",
    "Consider a six-sided fair dice (a standard dice used in board games) where each face is equally likely to land face up. The die has six faces, numbered 1 to 6. The Uniform Distribution can be applied to model the probability of rolling each number on the die. In this case:\n",
    "\n",
    "The minimum value (a) is 1 (the lowest number on the die).\n",
    "The maximum value (b) is 6 (the highest number on the die).\n",
    "\n",
    "In this Uniform Distribution:\n",
    "\n",
    "The probability of rolling a 1 is 1/6 (because there is 1 way to roll a 1 out of 6 possible outcomes).\n",
    "The probability of rolling a 2 is also 1/6.\n",
    "The probability of rolling a 3 is 1/6, and so on, up to 6.\n",
    "So, for each number on the die, the probability of rolling that specific number is the same, which is 1/6. This is an example of a discrete uniform distribution, where the possible outcomes are countable and finite (in this case, the six sides of the die).\n",
    "\n",
    "In summary, the Uniform Distribution is characterized by equal probabilities for all values within a defined interval. It is commonly used to model situations where each possible outcome has the same likelihood of occurring, as demonstrated in the example of rolling a fair six-sided die."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d6f8ba",
   "metadata": {},
   "source": [
    "#### Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d4840d3",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a statistical measure that quantifies how many standard deviations an individual data point is away from the mean (average) of a dataset. It is used to standardize and compare data points from different normal distributions.\n",
    "\n",
    "Formulae of z-score:-\n",
    "  z-score = (X-mean)/std\n",
    "  \n",
    "Importance of the z-score:\n",
    "\n",
    "=> Standardization: The z-score standardizes data, making it easier to compare and analyze data points from different distributions. It allows you to assess where an individual data point stands relative to the distribution's mean and how unusual or typical it is.\n",
    "\n",
    "=> Normalization: The z-score helps to normalize data, making it suitable for various statistical analyses, such as hypothesis testing, regression, and clustering. It removes the units of measurement, focusing solely on the data's relative position within the distribution.\n",
    "\n",
    "=> Identification of Outliers: Z-scores are useful for identifying outliers or extreme data points. Generally, data points with z-scores far from zero are considered outliers.\n",
    "\n",
    "=> Probabilistic Interpretation: The z-score can be used to calculate probabilities associated with specific data points in a normal distribution. It helps in answering questions like \"What is the probability of observing a data point this extreme or more extreme?\"\n",
    "\n",
    "=> Quality Control: In manufacturing and quality control, z-scores are used to monitor and control processes by detecting when data points deviate significantly from the mean, potentially indicating a problem in the process.\n",
    "\n",
    "=> Comparative Analysis: In research and social sciences, z-scores are used to compare individuals or groups on the same scale, even if the original data have different units of measurement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd76d463",
   "metadata": {},
   "source": [
    "#### Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d5d467f",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics and probability theory. It states that the distribution of the sample means (or sums) of a large enough number of independent, identically distributed random variables will be approximately normally distributed, regardless of the shape of the original population distribution. In other words, as the sample size increases, the sampling distribution of the mean approaches a normal distribution, even if the underlying population is not normally distributed.\n",
    "\n",
    "Significance of the Central Limit Theorem:\n",
    "\n",
    "=> Robustness: The CLT is crucial because it makes many statistical techniques and methods applicable to a wide range of real-world data. It allows statisticians and data analysts to assume a normal distribution for sample means, even when the original population is not normally distributed. This is especially useful when working with data that may have complex or unknown distributions.\n",
    "\n",
    "=> Inferential Statistics: The CLT forms the basis for many inferential statistics, including hypothesis testing and confidence interval estimation. It allows for the use of standard normal distribution tables and formulas to make statistical inferences about population parameters.\n",
    "\n",
    "=> Sample Size Determination: The CLT is often used to determine an appropriate sample size for a study. It helps in estimating the sample size required to ensure that the sample means closely follow a normal distribution, thereby improving the reliability of statistical analyses.\n",
    "\n",
    "=> Quality Control: In quality control and process monitoring, the CLT is used to assess the normality of sample means. Deviations from a normal distribution can signal problems in the manufacturing process, prompting further investigation.\n",
    "\n",
    "=> Econometrics: The CLT is crucial in econometrics and finance for modeling the behavior of financial returns, stock prices, and other economic variables, as it often allows for the use of normal distribution-based models and risk management techniques.\n",
    "\n",
    "=> Real-World Application: Many real-world phenomena, such as the heights of individuals, test scores, and measurement errors, can be analyzed and understood using the principles of the CLT. It provides a powerful and widely applicable framework for dealing with diverse datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5b814",
   "metadata": {},
   "source": [
    "#### Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c34407a9",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics, but it relies on certain assumptions to be valid. The key assumptions of the Central Limit Theorem are as follows:\n",
    "\n",
    "=> Random Sampling: The samples used in the CLT must be obtained through a random sampling process. This means that each observation in the sample should be independent of the others, and each observation should have an equal chance of being selected. Non-random or biased sampling can lead to violations of the CLT assumptions.\n",
    "\n",
    "=> Independence: The individual observations within a sample should be independent of each other. In other words, the outcome of one observation should not influence the outcome of another. This assumption ensures that the samples are not correlated.\n",
    "\n",
    "=> Finite Variance: The population from which the samples are drawn should have a finite variance. A population with an infinite variance or a variance that is changing over time may not satisfy the assumptions of the CLT.\n",
    "\n",
    "=> Identically Distributed: The random variables in the sample should be identically distributed. This means that each observation in the sample should come from the same probability distribution with the same mean and variance. It ensures that the samples are drawn from the same population.\n",
    "\n",
    "=> Large Sample Size: The CLT assumes that the sample size is sufficiently large. While there is no strict rule for what constitutes \"large,\" a common guideline is that the sample size should be at least 30. However, the larger the sample size, the better the approximation to a normal distribution. The choice of sample size depends on the specific problem and the degree of approximation needed.\n",
    "\n",
    "It's important to note that when these assumptions are met, the Central Limit Theorem states that the sampling distribution of the sample mean will approach a normal distribution as the sample size becomes large, regardless of the shape of the original population distribution. Violations of these assumptions can lead to inaccuracies when using the CLT, and alternative methods may be required for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102cb62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
